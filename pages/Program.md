title: Program

## IMPROTECH Paris -  &Alpha;&theta;&eta;&nu;&alpha; 2019

<br>
<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Thursday sept 26 - Opening
**Onassis Cultural Center, 18:00 - 22:30**
### Opening keynote and concert
</font>
<br>

#####18:00
#### Opening Words
A. Georgaki, C. Carras, G. Assayag, M. Chemillier

#####19:00
#### Keynote
George Lewis

##### 20:30 - 22:30
#### Concert #1

[*Program Notes*]({filename}/pages/ProgramNote_Concert1.md)

Evan Parker, Matt Wright, Peter Evans, Mark Nauseef (sax, electronics, trumpet, percussion)

Michelle-Agnes Magalhaes, Frederic Bevilacqua (composition, piano, gestural system)

Georg Hajdu: *Just Her - Jester - Gesture* (Lin Chen, augmented kalimba ; Georg Hajdu, live electronics),

Raphael Imbert / Benjamin Lévy  (Sax, traditional instruments, omax)

Students of UOA, Dimitri Vassilakis, Anastasia Georgaki, Raphael Imbert, Benjamin Lévy : *Omax & co* (Jazz ensemble, omax, dyci2)


<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Friday sept 27 - Lectures
**University of Athens, 09:00 - 14:00**
### Algorithms, AI and Improvisation
</font>
<br>

#####09:30
#### Keynote talk : Perception, embodiment, and expressivity in human and computer improvisation
George Tzanetakis

##### 10:15
#### It Ain’t Over Till Its Over: Theory of Mind, Social Intelligence and Improvising Machines
Ian Gold and Eric Lewis

##### 10:45
#### Improvising with augmented organ and singing instruments: gesture, sound, music (Cantor digitalis)
Christophe d’Alessandro

In this talk I present a reflection on my practice of improvisation with the augmented pipe organ and voice instruments.

In the augmented organ, the pipe sounds are captured, transformed and then played back in real time in the same acoustic space as the direct pipe sounds. Our augmented organ projects rely on three main aesthetic principles: microphony (proximal sound capture), fusion (of acoustic and electro-acoustic sounds) and instrumentality (no fixed support or external sound source). The augmented organ can be played in solo or duo (organist + live-electronics player). Solo performance is more challenging, as the organist must control additional interfaces, when his hands and feet are already busy with keyboard, pedalboard, expression pedals and combination and registration.<br>
Performative vocal synthesis allows for singing or speaking with the borrowed voice of another. The relationship of embodiment between the singer’s gestures and the vocal sound produced is broken. A voice is singing, with realism, expressivity and musicality, but it is not the musician’s own voice, and a vocal apparatus does not control it. These instruments allow for voice deconstruction, voice imitation, voice extension. Specific vocal gestures are replaced by hand gestures on control interfaces like graphic tablets, MPE keyboards, and even the (augmented) Theremin.<br>s
I will argue that the augmented organ (including extended techniques and new control interfaces) is in the continuity rather than the break with the organ improvisation tradition. Pipe organs are complex timbral synthesisers, which have always accompanied the evolution of music and technology. Improvising with performative vocal synthesis is a more disturbing experience: because linguistic meaning, vocal intimacy and personality are mixed or even confused in vocal performances, at the (possibly interesting) risk of an “uncanny valley” effect.


<font color="DarkBlue">
##### 11:15
#### *Coffee Break*
</font>

##### 11:45
#### Creativity, blending and improvisation: a case study on harmony
Emilios Cambouropoulos (School of Music Studies, Aristotle University of Thessaloniki)

One of the most advanced modes of creativity involves making associations between different conceptual spaces and combining seemingly unrelated constituent elements into novel meaningful wholes. Composers and improvisers often actively employ combinational and fusion strategies in producing original music creations. In this presentation we focus on issues of harmonic representation and learning from data, giving special attention to the role of conceptual blending in melodic harmonization. Models are presented for statistical learning of harmonic concepts (chord types and transitions, cadences and voice-leading) from musical pieces drawn from diverse idioms (such as tonal, modal, jazz, octatonic, atonal, traditional harmonic idioms). Then, a computational account of concept invention via conceptual blending is described that yields original blended harmonic spaces. The CHAMELEON melodic harmonisation assistant (new online version), produces novel harmonisations in diverse musical idioms for given melodies and, also, blends different harmonic spaces giving rise to new ‘unexpected’ outcomes.  Many musical examples will be given that illustrate the creative potential of the system. Such sophisticated blending methodologies can be incorporated in interactive improvisation systems allowing the creation and exploration of novel musical spaces (bypassing mere imitation).

##### 12:15
#### Do the math: Musical creativity and improvisation under the spectrum of information science
Maximos Kaliakatsos-Papakostas

Musical scores include information that is mostly sufficient to reproduce a musical work or the performance of an improvisational agent; this information can be considered as "low-level", if micro-timing, performance-specific or timbre-related information is disregarded. High-level structures emerge from patterns that combine low-level attributes: cadences, harmony and rhythm, among others, are higher-level constructions that build upon fine-grained combinations of low-level elements. Humans have the ability to implicitly identify such structures and readily employ them when listening, composing or improvising music, but to what extent can such human cognitive processes be algorithmically modelled? What would such modelling be practically good for? This lecture presents the problem of algorithmically modelling music cognition and creativity through methods of information science. Particular focus is placed on pattern extraction through generalisation (or information reduction) which is directly related to statistical learning. An intuitive presentation of the relations between these concepts and deep learning is given and, finally, some thoughts are openly discussed with the audience about how the latest advances in Machine Learning can be of practical use to the composer, the improviser or the music enthusiast.

##### 12:45
#### Children’s improvisations using reflexive interaction technologies – Computational music analysis in the European Project MIROR
Christina Anagnostopoulou, Aggeliki Triantafyllaki, Antonis Alexakis

While improvisation has been an essential component of music throughout history, its manifestation in children’s music-making is a debated issue (Azzara, 2002).  At the same time, research has revealed that improvisation is a significant aspect of children’s musical development and an important venue of creativity (Webster, 2002; Ashley, 2009). When children are improvising, particularly at an early stage of development, they usually try to express themselves without following any particular rules. Creativity then can emerge naturally (Koutsoupidou & Hargreaves, 2009). New technologies can support this natural development and help children develop their own musical style. <br>
The European Project MIROR (Musical Interaction Relying on Reflexion, mirorproject.eu) was based on a novel spiral design approach involving coupled interactions between computational and psycho-pedagogical issues. It introduced an AI-based improvisation system, the MIROR- IMPRO (Pachet et al. 2011), based on the original Continuator (Pachet 2003). The project integrated various psychological experiments, aiming to test cognitive hypotheses concerning the mirroring behaviour and the learning efficacy of the system, and validation studies aiming at developing the software in concrete educational settings. The philosophy behind the project was to promote the reflexive interactive paradigm not only in the field of music learning but more generally as a paradigm for establishing a synergy between learning and cognition in the context of child/machine interaction (Addessi et al. 2015).<br>
In the present paper we explore the thesis that the computational music analysis of children’s musical improvisations who use the above technology in order to find regularities and patterns of significance, can provide a useful addition and a valuable tool that can render even more constructively the blending of technology into children’s musical routine. On one hand, a tool is offered to assist the teacher in providing the musical dictions and on the other, the tool can provide the learner with a means which independently advances his/her musical capabilities through playful interaction. In order to achieve this, we employed specialised data-mining techniques and developed a set of lexicographically empowered investigation software tools to analyse the musical corpus produced by the children’s improvisations.  We present part of our results on the analysis on children’s improvisations, and we discuss the general advancements that the MIROR Project offered in the area of children’s improvisations.


<br>

<font color="DarkBlue">
##### 14:30
#### *Lunch Break*
UOA Cultural building Kostis Palamas
</font>
<br><br><br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Friday sept 27 - Workshops
**Onassis Cultural Center, 17:00 - 19:30**
### Body and Drama
</font>
<br>

##### 17:00
#### Kinaesonics: crafting and being trans-dimensional (Bodycoder system)
Mark Bokowiec, Julie Wilson-Bokowiec

In this workshop/demo we will unpack our particular approach to Kinaesonic composition and the multi-dimensional nature of our particular brand of live performance with the Bodycoder System. We will explore the critical intersections where liveness meets the programmed and the automated, consider the aesthetic as well as the socio-political implications and discuss the role and qualities of improvisation employed in the new work we will present at the Onassis Centre.   


##### 17:00
#### Haptic Feed-back Improvisation System
Claude Cadoz (ACROE, France)

##### 18:30
#### Interactive Drama Tools
George Petras, Panagiotis E. Tsagkarakis, Anastasia Georgaki

The use of novel interactive technologies in performative arts provide dynamic tools for improvisation and expressiveness of the actor/musician during a performance.<br>
Our research focuses on the development of interactive tools used in the context of ancient Greek Drama and Prosodic recitation.<br>
Firstly, we will present theoretical and practical aspects regarding the use of voice in drama performance.  How we use individual elements of ancient Greek prosody as also transposed ancient music theories (such as the curve of “logodes melos” by Aristoxenus) for the interactive process.<br>
Secondly, we’ll be presenting the technical and practical aspects regarding the interactive platform. We’ll be explaining areas like sensors, data extraction, mapping, and sound design.<br>
The interactive tools built to provide and develop the improvisation ability of the performer, in two ways: sonic improvisation and structural improvisation. The sonic improvisation is achieved by focusing on voice and sound processing, where the performer manipulates the sonic outcome in order to enhance the prosodic interaction and emotional meaning on the text. The structural improvisation allows the performer to move between scenes freely since he controls the ques with gestures and key positions in space.<br>
The workshop includes a short-term performance presenting the interactive platform in action. It aims to show how the theoretical, technical and performative aspects merge.

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Friday sept 27 - Concert
**Onassis Cultural Center, 20:30 - 22:30**
### _
</font>
<br>

##### 20:30
#### Concert #2

[*Program Notes*]({filename}/pages/ProgramNote_Concert2.md)

Bernard Lubat, Sylvain Luc, Gérard Assayag & Marc Chemillier (piano, guitar, Omax & dJazz systems)

Lara Morciano: *Philiris* (piano, motion capture, transducers and real-time electronics)

George Lewis, Evan Parker, Mari Kimura, Stylianos Dimou: *Voyager: Interactive Quintet* (2007/2019) (trombone, sax, violin, live electronic, voyager system)

Pierre Couprie, Gyorgy Kurtag, Mari Kimura, Hugues Genevois (live Electronics, Gesture interface, violin/MUGIC™ sensor)

Rémy Fox, J. Nika (saxs, DYCI2 system)

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Saturday Sept 28 - Lectures
**University of Athens, 09:00 - 14:00**
#### Improvisation, Digital Intelligence and Cultural Heritage
</font>
<br>

##### 09:30
#### Keynote talk : From Digital to Human Intelligence in Music Understanding Research
Xavier Serra (Music Technology Group, Universitat Pompeu Fabra, Barcelona)


We are able to develop AI algorithms that solve complex musical tasks, yet, we are unable to apply these powerful technologies to help understand and improve our own musical comprehension abilities. Our machines are rapidly becoming capable of “understanding” music, while we still use traditional and time-consuming educational methods for training people in the development of their basic musical skills, or for that matter, in the development of most cognitive-based human capabilities. To make sense of a particular music listening experience, as listeners we identify relevant auditory cues and then piece the cues together into patterns that can be retained long enough for brain mechanisms to examine and create the impression of auditory objects. Music lovers that appreciate and comprehend a particular musical style are able to verbalize their cognitive experience after listening to a music piece of that style. In this talk we propose that by building on prior research from the fields of Music Cognition, Music Information Retrieval, and Music Education we should be able to develop tools and perceptual training methodologies with which to help a naive listener to understand and apreciate a music tradition to which they had no prior exposure. Given that computers will never be able to comprehend or feel for us, we should do our best to build systems that can help us with that.

##### 10:15
#### Modelling Improvisation Systems in the Mediterranean Sphere
Mondher Ayari

##### 10:45
#### " Jazz Mapping ” : Thematic Development and Story Telling in Jazz Improvisation
Dimitri Vassilakis

“Jazz  mapping"  is  a  multi-layer  analytical  approach  to jazz  improvisation  based  on  hierarchical  segmentation and categorization of segments, or constituents, according to their function in the overall improvisation. In this way higher-level semantics of transcribed and recorded jazz solos can be exposed. In this approach, the knowledge of the expert jazz performer is taken into account in all analytical decisions.  We  apply  the  method  to  two  well-known  solos,  by  Sonny  Rollins  and  Charlie  Parker  and we  discuss  how  improvisations  resemble  storytelling, employing  a  broad  range  of  structural,  expressive,  technical and emotional tools usually associated with the production  and  experience  of  language  and  of  linguistic meaning. We  make  explicit  the  choices  of  the  experienced jazz improviser who has developed a strong command over the language and unfolds a story in real time, very similar to prose on a given framework, He/she utilizes  various  mechanisms  to  communicate  expressive intent, elicit emotional responses, and make his/her musical “story,” memorable and enjoyable to fellow musicians and listeners. We also comment on potential application areas of this work related to music and artificial intelligence.

<font color="DarkBlue">
##### 11:15
#### *Coffee Break*
</font>

##### 11:45
#### Metrical Polyrhythms and Polytemporality in live Improvisation Settings
Sami Amiris, Antonis Ladopoulos

##### 12:15
#### GesTCom as an Interactive Tool for Improvisation
Pavlos Antoniadis

In the proposed lecture, I will present the use of the system GesTCom as an interactive tool for improvisation, in the context of my collaboration with the composer and improviser Panos Ghikas.<br>
The GesTCom (Gesture Cutting through Textual Complexity) has been developed at IRCAM since 2014, in collaboration with the Interaction-Son-Musique-Mouvement team. It is a modular sensor-based environment for the analysis, processing and real-time control of complex piano notation through multimodal recordings. In terms of hardware, it comprises systems for the capture of movement, audio, video, MIDI and capacitive data from sensors on the piano keys. In terms of software, it is equipped with modules for the capture, analysis and control of the multimodal data; and modules for the augmentation and interactive control of music notation. Each of these systems functions both as stand-alone and integrated in a general methodology denoted as embodied navigation of complex notation.<br>
The collaboration with Ghikas resulted in three distinct projects: Open Cycles (Bath, 2016), Toxic Gum (Berlin, 2017) and Azoman (London, 2018). I will present audiovisual material and patches from these three collaborations, which next to the GesTCom feature Ghikas's unreal-time improve system. I will show how the GesTCom was used both as a generator of pre-compositional material and as a real-time tool enabling allelomimetic interactions based on gesture in both solo, duo and ensemble settings.  I will also expand on the underlying concepts of embodied navigation of complex notation and of unreal-time improv as promoting the complementarity of improvisation and composition and the fluidity between notation, motion and sound in piano performance.

##### 12:45
#### Disposable Music
Georg Hajdu

My presentation introduces the concept of real-time composition and composition as a dispositif in the sense of Foucault and Deleuze, defining it as a heterogeneous ensemble of pieces which together form an apparatus. The introduction situates the dispositif in the context of cultural developments, most notably its slow, but steady shift away from textualization in digital media. As musicians are adapting to ensuing cultural and, above all, economic changes, new music forms emerge which rely to a lesser degree on fully-notated scores such as comprovisation or laptop performance. Antithetically, the computer also allows the creation of “author-less” notated scores in real-time to be sight-read by capable musicians—a practice for which special software has been developed in recent years. Since these scores are not meant to be kept and distributed, they are ephemeral and, therefore, disposable. Examples are given to illustrate the interwovenness of this approach, where carefully selected narratives and dramaturgies make up for the inherent unpredictability of the outcome.

<br>

<font color="DarkBlue">
##### 14:30
#### *Lunch Break*
UOA Cultural building Kostis Palamas
</font>
<br><br><br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Saturday sept 28 - Workshops
**Onassis Cultural Center, 17:00 - 19:30**
### Game, mobiles, transducers
</font>
<br>

##### 17:00
#### The Dynamic Percussion System: A procedural music engine for video games
Daniel Brown

The Dynamic Percussion System is software used in commercial video games like Rise of the Tomb Raider (2015) that composes procedural percussion music that adapts to game action in real time.<br>
While the use of procedural music in video games is an exciting development, there are many unanswered questions and issues surrounding it. How does it fit into the traditional workflow of professional composers and sound designers? What choices do such people have when “authoring” procedural music? How does it interact with precomposed game music?  
The Dynamic Percussion System comprises both an in-game playback system and an authoring tool to be used by composers and sound designers. The design of the authoring tool––its user interface and functionality––addresses these questions. It offers one model of how the new techniques of generating procedural music can be adapted into the traditional methods used in commercial development. It has also motivated new techniques for generating, implementing, and interpreting game music.


##### 17:00
#### COMO : Movement-based collective improvisation using mobile devices
Frédéric Bevilacqua (Ircam), Michelle-Agnes Magalhaes, composer

##### 18:30
#### Composition / improvisation in “musiques mixtes” with captors and transducers
Lara Morciano (composer), Jose-Miguel Fernandez (composer, Ircam)

##### 18:30
#### Improvisation with Motion Sensors and Live coding: Combining Dance and Instrumental Improvisation
Ioannis Zannos

This workshop introduces techniques of improvisation with wearable movement sensors combined with live coding.  Movement sensors based on IMU (Inertial Measurement Units) are used to measure the movement of a performer.  The motion data is transmitted to computer over wifi, and live coding is used to control the generation of sound in SuperCollider and graphics on the Godot Gaming engine.  The workshop shows how to use the sc-hacks library in order to program and modify the response of the system to sensor data.  Techniques for sending the control data to remote locations over the internet are shown.  This enables joint performance from several different remote locations. At each location the data sent from all performers is used to synthesize the audiovisual performance.

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Saturday sept 28 - Concert
**Onassis Cultural Center, 20:30 - 22:30**
### _
</font>
<br>

##### 20:30
#### Concert #3

[*Program Notes*]({filename}/pages/ProgramNote_Concert3.md)

Jaap Blonk, Hervé Sellin, Georges Bloch: *Cine-concert*, (voice, piano, DYCI2 system)

Mark Bokowiec, Julie Wilson - Bokowiec: *HEXIS* (Kinaesonic, Bodycoder System)

Marc Chemillier & Camel Zekri: *Machines and Gnaoua tradition* (strings, dJazz system)

Orestis Karamanlis, Areti Andreopoulou (UOA): *Traditional musicians* (Laptop / musicians performance)

Steve Lehman, J. Nika (saxs, DYCI2 system)

<br>
<br>


<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Sunday Sept 29 - Lectures
**University of Athens, 09:00 - 14:00**
#### Aesthetics and Ethics of Improvisation in the Digital Era
</font>
<br>

##### 09:30
#### Keynote talk :
Gary L. Hagberg (Bard College, US)

##### 10:15
#### The MICA Project : Musical Improvisation and Collective Action
Clement Canonne & Pierre Saint Germier

*Pierre Saint Germier: Interaction and Improvisation in Human and Artificial Musicians. A conceptual approach<br>
In this talk, I will first discuss conceptual analyses of the notions of interaction and improvisation in music from the standpoint of the philosophy of action. In particular, I will contend that interaction and improvisation are best conceived as overlapping but importantly distinct notions. I will also present and evaluate a set of positive criteria for improvised action (as opposed to merely negative criteria such as "unplanned" or "unscripted"). In the second part of the talk, I will discuss how these notions can be applied to music-making settings involving artificial entities, such as software or robots.*

##### 10:45
#### Machine Ethics and Music Creativity
George Kosteletos, Αnastasia Georgaki

While tackling the issues of Machine Ethics from the perspective of possibly intelligent machines, one has to face questions related to the attribution of rights to such mechanical entities. Given that in the last seven or more decades computational systems have been involved in the production of more or less organized sound structures characterized as works of art, one of the machine rights in question is the right of authorship. In its turn, this right is interconnected with a set of other rights and questions like copyright issues (the legal and financial side of the right of authorship), one’s right to be appreciated for one’s own work as well as questions regarding the ontology of the mechanic output (Is it an artistic or just an aesthetic object?). However, answering these questions presupposes the attribution of intelligence to the machines involved in the production of such an output. Could the production of an aesthetically laden output be thought of as a genuine manifestation of intelligence or do we need the application of extra criteria? Our previous experience of designing and running various forms of musical Turing Tests (musical TT) has shown that the criterion of music creativity suffers from the same problems and limitations of any other intelligence criterion applied in the past. Nevertheless, there seems to be a special case of music creativity: music improvisation. So the question arises: Could music improvisation with its spontaneous and dialectical (in the case of human-machine interaction in the context of live electronics) nature be a safe indication of machine intelligence, bypassing the problems of traditional intelligence criteria? Two case studies of music improvisation AI systems are examined.

<font color="DarkBlue">
##### 11:15
#### *Coffee Break*
</font>

##### 11:45
#### AI-Aesthetics. Artificial Intelligence in Music and Art
Harry Lehmann

In the field of Artificial Intelligence (AI), impressive progress has been made in recent years, especially due to the development of deep learning systems. After the first applications of such programs in art and music, it is becoming apparent that a new aesthetic discipline could develop here (in analogy to how advances in computed tomography led to the formation of neuroaesthetics two decades ago). The obvious suggestion would be to speak of AI-aesthetics here. Thus, for example, a deep learning system was trained to abstract the corresponding stylistic features from many examples of a particular painting style, such as Cubism or Expressionism. As a result, it became possible to convert any photo, such as your own portrait, into a Cubist or Expressionist style.<br>
The aim of my lecture will be, on the one hand, to describe the phenomena that fall within the scope of such AI-aesthetics. These include works of art and musical compositions that were 'calculated' using AI programs. Similarly, recommender systems that make aesthetic decisions using AI algorithms fall into this area. On the other hand, I would like to try to gauge the consequences of this for both art and music as well as art and music theory.

##### 12:15
#### The phenomenology of computer aided improvisation and the constitution of the virtual music subject
Iakovos Steinhauer, Anastasia Georgaki

Improvisation is a practice free from any pre-established system, based mainly in interaction, namely the aim to become a part of the other, to feel, think and act not only following the subjective assessments but by adapting the play behavior of the improvisation partner. In case of improvisation between a player and the computer music derives from a continuous circuit of mediations, complex real time- interactive responses to the musician’s playing. The computer aided improvisation provides empirical insight into the reversible, dialectical, and signifying nature of a virtual embodiment, where the player acts by feeling his limited body in interaction with an incomplete, not yet self conscious but potential limitless body-subject. The purpose of this paper is to undertake philosophical reflections upon computer assisted improvisation. We see the digital improvisation experience as a process that finds its foundation in a mutually shared space, constituting both the augmented subjective musical body of the musician and the virtual computer subject, providing new forms of self consciousness in creation.

##### 12:45
#### Improvising (with) awkwardness
Danae Stefanou

In modern Greek, the term “amechania” roughly translates as “awkwardness”. It owes its name to the ancient Greek deity of Helplessness, a spirit linked to times of crisis and want. Literally translatable as a “de-machination”, it essentially describes the critical state when a mechanism fails, and otherwise automated procedures are rendered inoperative. Yet, unreliable systems and failing machines, whether in the form of technological apparatuses or cognitive procedures, also tend to yield their own unforeseen byproducts. When a machine is de-instrumentalised, when its prescribed function is not executable and its use no longer discernible, divisions between subject and object, freedom and control, process and product may be more easily exposed, unpacked, and relativized. Discussing such liminal instances in recent examples of improvised music, I examine the broader theoretical implications of this concept, with reference to the work of Giorgio Agamben and Donna Haraway among others, and propose an active exploration of amechania as a positive aspiration for experimental and improvised music-making in the age of machinic capitalism.

##### 13:30
#### Round table & closing address

<br><br>

<font color="DarkBlue">
##### 14:30
#### *Lunch*
UOA Cultural building Kostis Palamas
</font>
<br><br><br>



---

<p align="center">
   <br><br>
  <img src="../images/IKPoster_frag10.png" width="300">
   <br><br>
</p>
f
