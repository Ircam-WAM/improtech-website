title: Programme

---


Access to lectures and workshop is free, but reservation is mandatory **[here.]({filename}/pages/Venues.md)**
Access to Ircam concerts is through Ircam web page.
Access to Dynamo is through the Dynamo web page.


- [Workshops and Lectures](#29-july-monday)
- [Improtech Concerts #1 and #2](#2-august-friday)
- [Lectures Abstracts](#abstracts)
- [Improtech COncert at the Dynamo]({filename}/pages/Programoff.md)


## December 2 Tuesday

### 20:00 IMPROTECH CONCERT #1 at Espace de Projection, Ircam

**Psappho, after Iannis Xenakis**  
Lorenzo Colombo percussions  
Marco Fiorini   AI-Agents Somax2, live  electronics

**Décembre - premier livre du cycle Arc’**  
Marco Suárez-Cifuentes composition, AI-Agents Somax2  
Johanna Vargas voice  
Nicolas Crosse bass  
Aurélien Gignoux drums  
Nieto texts  

**Traversée III**  
Nicolas Brochec composition, AI-Agents Somax2  
Kanami Koga flute  

**REACHin’ Marseille**  
Turner Williams Jr shahi baaja  
György Kurtág Jr synthetisers  
Jean-Marc Montera guitars, electronics  
The Who/Men (Gerard Assayag, Mikhail Malt, Marco Fiorini AI-Agents Somax2)  
Feat.Mari Kimura, violon, Pierre Couprie, live électronics  

**Deleph**  
Jaap Blonk voice, sound poetry  
Benny Sluchin trombone  
Georges Bloch AI-Agents Omax5, Somax2  

**In albireo luogo…**  
Lara Morciano composition  
Joëlle Léandre, Nicolas Crosse bass  
José-Miguel Fernandez AI-Agents Somax2Collider, immersive electronics  


## December 5 Friday

### 20:00 IMPROTECH CONCERT #2 at Espace de Projection, Ircam


**Artisticiel**  
Bernard Lubat piano, voice  
Gérard Assayag AI-Agents Omax & Somax2  
Marc Chemillier AI-Agents Djazz  

**Solo for sliding Trombone**  
After John Cage composition  
Benny Sluchin trombone  
Mikhail Malt AI-Agents Somax2,  immersive electronics  

**Taideji**  
Lara Morciano compposition, piano  
Thierry Miroglio percussions  
Jose-Miguel Fernandez AI-Agents Somax2, immersive electronics  

**Transe III**  
Justin Vali Malagasy Zither, voice  
Marc Chemillier AI-Agents Djazz  
NSDOS electronic hack, live coding, dance  

**NaN - Not a Number**  
Alberto Gatti composition, immersive electronics, AI-Agents Somax2  
Anaïs del Sordo voice  

**in memoriam Susan Alcorn**  
Miya Masaoka composition, koto  

**SoVo II**
George Lewis composition  
Joëlle Léandre bass, voice
Miya Masaoka koto  
Marco Fiorini, SoVo AI system, pianos Disklavier, immersive audio

## December 7 Sunday

### 18:00 IMPROTECH CONCERT #3 at La Dynamo, Pantin

**REACHin' Paris**  
Steve Lehman, Saxophones  
Miles Okazaki, Guitar, Somax2 AI Agents  
The Somax Brothers (Gérard Assayag, Marco FIorini) Somax2 AI Agents  

*This concert follows a Master-Class in the afternoon with the same musicians.*

## December 6 Saturday

### 14:00  - 19:00 INSTALLATIONS / PERFORMANCES in Studio 5, Ircam  

**WWW**  
José-Miguel Fernandez composition, AI-Agents Somax2Collider, immersive electronics  
Amaryllis Billet, Philippe Bord, Nicolas Chedmail, Roméo Monteiro, Maxime Morel, Joris Rühl, Spat'Sonore physical spatialisation installation  

**Batterie Fragile**  
Yves Chaudouet inventor of the Fragile Drum  
Jean-Brice Godet, clarinettes  
Thierry Miroglio, Aurelien Gignoux, percussions  
NOSFELL, oices  
Somax Brothers, AI Agents Somax2 / Somax2Collider  


## December 3, wednesday  

### 10h - 13h Workshop *Resounding Bodies*  in Studio 2, Ircam  

Alberto Gatti, composer, designer  
Anaïs del Sordo, voice, body harness  
Marco Fiorini Spatial Agents Somax2  

### 14h - 19h Workshops in Studio 5, Ircam 

**Breathing Media Project**  
Tamami Tono, Sho  
Minako Ito, Bugaku dance  
Todokoro, ideo  

**Mugic Magic**  
Mari Kimura, Mugic sensors, violon  


**Sophtar**  
Federico Visi, Sophtar Instrument, Somax2  

**Boulez Reloaded : Notations**  
Alain Blesing, Guitare électrique, Somax2  


## December 4, Thursday  
### 14h - 19h Workshops in Studio 5, Ircam 

**Boulez Rebooted and other projects**  
Levy Lorenzo, percussion, live electronics, somax2

**PURE MALT *Augmented Improvisations: from instrumental gesture to telematics***  
Mikhail Malt, Somax2, live electronics, telematics  
Cassia Carrascoza, flute, telematics  
Li Chin Li, sheng  

** DjazzTok  **  
Yohann Rabearivelo, AI Agents Djazz, TikTok, Video  
Heny Zouary, Violin  


**Activate Cities**  
NSDOS (Kirikou Des) electro-hack, dance
Noam Assayag litterature, voice  


## December 5, Friday  
### 11h - 13h Workshops in Studio 5, Ircam 

**Metagorminx**  
Gyorgy Kurtag, synthesizers  
Donatien Garnier, Metagorminx instrument, poetry  
Emmanuelle Pépin, dance  

**Sardines**  
Guillaume Piccarreta, synthesizers  
Raphaël Forment, Rémi Georges, live coding


## December 4, Thursday  
### 9h30 - 13h Lectures in Stravinsky hall, Ircam 

Ken Deguernel Méthodes Co-Créatives pour des Partenariats Musicaux Humain-IA de Longue Durée  (ANR MICCDroP)  
Alain Bonardi Generative Spatial Synthesis of Sound and Music (ERC G3S)  
Makis Solomos Xenakis Reloaded in the age of AI, the case of Psappho  
BREAK   
Pierre Saint Germier  Inside Artificial Improvisation (ANR InAI)  
Pierre Couprie  Advances in Interactive Electroacoustic improvisation  
Nicolas Brochec, Marco Fiorini  Extended Instrumental Techniques Recognition for Generative Coimprovisation  


## December 5, Friday  
### 14h - 19h Lectures in Stravinsky hall, Ircam 
Sivan Eldar, Jean-Louis Giavitto, Augustin Muller Like Flesh, Nine Jewel Deers, composition and improvisation  
Oded Ben Tal , David Dolan  "The Odd Couple - Human & AI  
Making Music in the Moment"  
Daniel Brown  Unity interface to Generative Improvisation Agents  
Jean-Rémy Guédon  ArchiMusic Reloaded wit no-code generative AI  
Gilbert Nouno, Christophe Fellay  Evaluation of AI based improvisation systems  
Nicolas Souchal, Diemo Schwartz Extense : collective and human-machine agentivity  


<br>

## Abstracts


**[Miller Puckette](https://www.labiennale.org/en/music/2023/silver-lion)** (Ircam), **[Irwin](https://grayarea.org/community-entry/irwin-and-miller/)**, An inside view of an instrument


Signal delays are very bothersome to live musicians, especially percussionists.  As a duo using percussion, we have worked out a way to avoid having to send audio signals between computers, which would always add some delay.  Instead, we  work as a duo within one computer by making plug-ins that can be remotely controlled. The plug-ins can be any kind of patch, either Max or Pure Data, and can be hosted by any digital audio workstation.  The result is a single software percussion instrument played live by a musician but simultaneously played by a second performer using controllers that act within one or several plug-ins in a single signal chain.


**Marc Chemillier** (EHESS), Keeping the swing, AI cocreative musicianship in collective idiomatic settings


Artificial intelligence can be seen as antagonistic to certain traditional activities, particularly music. We are going to criticize this stereotype by showing how machine learning can be used for music with an oral tradition. During the REACH project, we developed an improvisation software programmed in Max/MSP, which has the particularity of taking a regular pulse into account. All pulse-based musical sequences captured by the software can be reused after the learning phase, retaining the same culturally relevant rhythmic position. The improvisation software is thus able to play in the style of native players. The outputs of the program are good enough to allow duets between a musician and the computer. Musicians reacting to the outputs of the machine can shed new light on the analysis of their repertoires. By refining the generation parameters, we can get closer to an optimal characterization of the music studied. We’ll show examples of experiments with musicians from Madagascar. Moreover, the system can also explore various degres of hybridation. One can inject in the context of Malagasy music generated solos from other traditions (for instance jazz) and study how it fits the musical context according to the native musicians point of view, which can shed new light on the boundaries of a given musical tradition.


**[Shlomo Dubnov](https://en.wikipedia.org/wiki/Shlomo_Dubnov)** (UCSD, Qualcomm Institute), Advanced Machine Learning and Music Information dynamics for Deep and Shallow CoCreative Systems

In the talk Shlomo Dubnov will survey his recent research on advanced generative music AI methods with emphasis on diffusion methods and information theory. He will then describe creative applications of text-to-music, voice conversion and multi-track synthesis, and analysis of polyphonic music in terms of multi-information dynamics. Questions of co-creativity, artistic sensibility and Kansei in AI will be discussed.


**[Nicolas Brochec](https://nicolasbrochec.com)**, **[Marco Fiorini](https://forum.ircam.fr/profile/fiorini/)** (Geidai, Ircam) : Real-Time Recognition of Instrument Playing Techniques for Mixed Music and CoCreative Interaction


We are going to detail the techniques, methodologies, and outcomes that led to the development of an interactive system based on real-time Instrumental Playing Technique (IPT) recognition. Starting from exploratory studies on the flute, we will discuss soundbank recording, data format, and data augmentation, as well as state-of-the-art machine learning model architectures developed in our research. By connecting our model to the co-creative AI system Somax2, we are able to interact with generative agents by means of real-time recognition of IPT classes, adding a new dimension to its interaction paradigm and addressing potential scenarios of co-creative human-machine interaction in mixed music for improvisation and composition.


**[Mari Kimura](https://www.marikimura.com/)** (UC Irvine), MUGIC®: endless possibilities extending musical expression

MUGIC® is a 9-axis motion sensor similar to other generic 9-axis sensors available on the market. However, what sets MUGIC® apart is its comprehensive, user-friendly design. Created by violinist and composer Mari Kimura, MUGIC® is a turnkey product that allows musicians to create their art immediately without requiring extensive programming or electrical engineering skills. The first version of MUGIC® sold out following a significant bulk order from the Lincoln Center in NYC this spring. As MUGIC® v.2 is under development, Kimura will demonstrate the importance of fostering a community around new technology and how MUGIC® users are expanding its application not only in music but also in other forms of art and beyond.


**[Jose-Miguel Fernandez](https://brahms.ircam.fr/en/jose-miguel-fernandez)** and **[Lara Morciano](https://brahms.ircam.fr/en/lara-morciano)** (Ircam) Composition and Interaction with Somax2


In this presentation, we will discuss the integration of Somax2 into musical composition through the works of Lara Morciano and José Miguel Fernández. We will also present the Somax2Collider environment for Spatial Interactive Agents, which is a preliminary approach to using agents in the context of spatialized improvisation using the SuperCollider software and a system of wireless connected speakers.


**[Nao Tokui](https://neutone.ai/blog/meet-the-team-nao-tokui)** (Qosmo Inc.), Surfing musical creativity with AI — what DJing with AI taught me


Nao Tokui discusses the progression of his AI DJ project, which incorporates machine learning systems for live performances, and shares the insights he gained from it. He also explores the potential implications of the latest AI technology in music improvisation.


**[Steve Lehman](https://www.stevelehman.com/)** , Professor of Music at CalArts, Current Trends in Computer-Driven Interactivity with Tempo-Based Rhythm


Steve Lehman will present a survey of current trends in experimental musics that draw from tempo-based modalities of rhythm, with a particular focus on their application to computer-driven models for real-time interaction. 




---

<br>
<p align="center">
  <img src="../images/Logo_improtech_anniv.png" width="300">
</p>
<br>

<br>

<br>
<p align="center">
  <img src="../images/ikUZESTE_logos.png" width="2800">
</p>
<br>
