title: Program summary
Status: Hidden

## IMPROTECH Paris -  &Alpha;&theta;&eta;&nu;&alpha; 2019

<br>
<br>
<br>

[TOC]

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">  
<font color="DarkBlue">
# Thursday sept 26 - Opening
**Onassis Cultural Center, 18:00 - 22:30**
### Opening keynote and concert
</font>
<br>



***18:00 - 19:30***
#### Opening Words
Anastasia Georgaki, Christos Carras, Gérard Assayag, Marc Chemillier

#### Opening Keynote
George Lewis (Columbia University)

<br>

***20:00 - 22:30***
#### Concert #1

[*Program Notes*]({filename}/pages/ProgramNote_Concert1.md)

**Evan Parker, Matt Wright, Peter Evans, Mark Nauseef**  
*Trance Map+*  
Saxophones, live electronics, trumpet, percussion

**Michelle-Agnes Magalhaes, Frederic Bevilacqua & guests**  
*In good company*  
for 2 pianists, guest musicians and webaudio devices

**Georg Hajdu**  
*Just Her - Jester - Gesture*  
For augmented kalimba (played by Lisa Chen) and live electronics

**Raphael Imbert, Benjamin Lévy**  
*A.I. Swing*  
Saxophones, OMax 5 computer system

**Dimitri Vassilakis with the students from the University of Athens**  
*Guests : Anastasia Georgaki, Raphael Imbert and Benjamin Lévy*  
Saxophones, guitars, vocals, accordion, live electronics, OMax 5 and DYCI2 computer system  

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Friday sept 27 - Lectures
**University of Athens, 09:30 - 13:30**
### Algorithms, AI and Improvisation
</font>
<br>
<br>

#### Keynote talk : Perception, embodiment, and expressivity in human and computer improvisation
George Tzanetakis (University of Victoria, Ca)

#### It Ain’t Over Till Its Over: Theory of Mind, Social Intelligence and Improvising Machines
Ian Gold and Eric Lewis (McGill University, Ca)

#### Improvising with augmented organ and singing instruments: gesture, sound, music (Cantor digitalis)
Christophe d’Alessandro (Sorbonne University, Fr)

#### Creativity, blending and improvisation: a case study on harmony
Emilios Cambouropoulos (Aristotle University of Thessalonikin, Gr.)

#### Do the math: Musical creativity and improvisation under the spectrum of information science
Maximos Kaliakatsos-Papakostas (Ionian University, Gr.)

#### Children’s improvisations using reflexive interaction technologies – Computational music analysis in the European Project MIROR
Christina Anagnostopoulou, Aggeliki Triantafyllaki, Antonis Alexakis (University of Athens, Gr.)

<br><br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Friday sept 27 - Workshops
**Onassis Cultural Center, 16:00 - 19:00**
### Body and Drama
</font>
<br>
<br>

#### Kinaesonics: crafting and being trans-dimensional (Bodycoder system)
Mark Bokowiec, Julie Wilson-Bokowiec (University of Huddersfield, UK)

***17:00 - 18:00***
#### Interactive Drama Tools
George Petras (National School of Dance, Gr.), Panagiotis E. Tsagkarakis (Free-lance Engineer), Anastasia Georgaki (University of Athens, Gr.)

***18:00 - 19:00***
#### Collective performance and improvisation using CoMo-Elements
Michelle Agnes Magalhaes (composer, Ircam, Fr.), Frédéric Bevilacqua (researcher, Ircam, Fr.)

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Friday sept 27 - Concert
**Onassis Cultural Center, 20:00 - 22:30**
<br><br><br>
</font>
<br>
<br>

***20:00 - 22:30***
####  Concert #2

[*Program Notes*]({filename}/pages/ProgramNote_Concert2.md)  

**Bernard Lubat, Sylvain Luc, Marc Chemillier, Gérard Assayag**  
*Lubax Lux*  
Piano, guitar, Omax & dJazz computer systems

**Lara Morciano**  
*Philiris*  
For piano, motion capture, transducers and real-time electronics

**George Lewis, Evan Parker, Mari Kimura, Stylianos Dimou, Voyager**  
*Voyager: Interactive Quintet* (2007/2019)  
Trombone, saxophones, violin, live electronics, Voyager interactive pianist.

**Mari Kimura, Pierre Couprie, Gyorgy Kurtag, Hugues Genevois**  
*A Close Encounter of the Seventh Kind*  
Violin, live electronics, Handsonic, Koncertdoboz

**Rémi Fox, Jérôme Nika**  
 *C’est pour ça*  
Saxophones and DYCI2 computer system

<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Saturday Sept 28 - Lectures
**University of Athens, 09:30 - 13:30**
#### Improvisation, Digital Intelligence and Cultural Heritage
</font>
<br>
<br>

***09:30***
#### Keynote talk : From Digital to Human Intelligence in Music Understanding Research
Xavier Serra (Universitat Pompeu Fabra, Sp.)


We are able to develop AI algorithms that solve complex musical tasks, yet, we are unable to apply these powerful technologies to help understand and improve our own musical comprehension abilities. Our machines are rapidly becoming capable of “understanding” music, while we still use traditional and time-consuming educational methods for training people in the development of their basic musical skills, or for that matter, in the development of most cognitive-based human capabilities. To make sense of a particular music listening experience, as listeners we identify relevant auditory cues and then piece the cues together into patterns that can be retained long enough for brain mechanisms to examine and create the impression of auditory objects. Music lovers that appreciate and comprehend a particular musical style are able to verbalize their cognitive experience after listening to a music piece of that style. In this talk we propose that by building on prior research from the fields of Music Cognition, Music Information Retrieval, and Music Education we should be able to develop tools and perceptual training methodologies with which to help a naive listener to understand and apreciate a music tradition to which they had no prior exposure. Given that computers will never be able to comprehend or feel for us, we should do our best to build systems that can help us with that.

***10:15***
#### Forms of presence in instrumental and electronic improvisation in relation to  cultural contexts
Marc CHemillier (EHESS, Fr.)

The development of digital sounds and live music softwares has profoundly changed the notion of "presence" in music. Connected to the philosophical tradition of ancient Greece (parusia in Plato, παρουσία), this notion of presence is translated into music by different types of relationships between musicians within an orchestra or between musicians and their listeners. They take extremely varied forms depending on the culture, from the ritualised and participatory music of societies with an oral tradition to the musical flow that nowadays is delivered through streaming platforms. The development of improvisation software profoundly renews this notion of presence and invites us to reflect on what distinguishes its different forms. Several examples will be given from work with the improvisation software Djazz (digitaljazz.fr) in different cultural contexts.

***10:45***
#### " Jazz Mapping ” : Thematic Development and Story Telling in Jazz Improvisation
Dimitri Vassilakis (University of Athens, Gr.)

“Jazz  mapping"  is  a  multi-layer  analytical  approach  to jazz  improvisation  based  on  hierarchical  segmentation and categorization of segments, or constituents, according to their function in the overall improvisation. In this way higher-level semantics of transcribed and recorded jazz solos can be exposed. In this approach, the knowledge of the expert jazz performer is taken into account in all analytical decisions.  We  apply  the  method  to  two  well-known  solos,  by  Sonny  Rollins  and  Charlie  Parker  and we  discuss  how  improvisations  resemble  storytelling, employing  a  broad  range  of  structural,  expressive,  technical and emotional tools usually associated with the production  and  experience  of  language  and  of  linguistic meaning. We  make  explicit  the  choices  of  the  experienced jazz improviser who has developed a strong command over the language and unfolds a story in real time, very similar to prose on a given framework, He/she utilizes  various  mechanisms  to  communicate  expressive intent, elicit emotional responses, and make his/her musical “story,” memorable and enjoyable to fellow musicians and listeners. We also comment on potential application areas of this work related to music and artificial intelligence.

<font color="DarkBlue">
***11:15***
#### *Coffee Break*
</font>

***11:45***
#### Metrical Polyrhythms and Polytemporality in live Improvisation Settings
Sami Amiris (American College, Athens Big Band, Gr.), Antonis Ladopoulos (University of Athens, American College, Gr.)

Artistic explorations of two improvising musicians who dare to dwell on the fringe of polytemporality and metrical polyrhythmicity.
The musicians forming the critically acclaimed Phos Duo, expand their horizons by each expanding on distinct metrical surfaces - thus each one has a different sense of the whole than the other, like observers with different speeds in the theory of relativity - while still listening to each other and interacting.
To make this possible in practice, a new type of metronomic sequencer - like an individual mechanical conductor - is used, capable of handling different timings simultaneously and independently from channel to channel, but still controllable overall.
The result is an exciting and challenging musical environment that the duo finds fruitful for the creation of new musical textures, both through-composed and improvised.


***12:15***
#### GesTCom as an Interactive Tool for Improvisation
Pavlos Antoniadis (musician and musicologist, Fr.)

In the proposed lecture, I will present the use of the system GesTCom as an interactive tool for improvisation, in the context of my collaboration with the composer and improviser Panos Ghikas.<br>
The GesTCom (Gesture Cutting through Textual Complexity) has been developed at IRCAM since 2014, in collaboration with the Interaction-Son-Musique-Mouvement team. It is a modular sensor-based environment for the analysis, processing and real-time control of complex piano notation through multimodal recordings. In terms of hardware, it comprises systems for the capture of movement, audio, video, MIDI and capacitive data from sensors on the piano keys. In terms of software, it is equipped with modules for the capture, analysis and control of the multimodal data; and modules for the augmentation and interactive control of music notation. Each of these systems functions both as stand-alone and integrated in a general methodology denoted as embodied navigation of complex notation.<br>
The collaboration with Ghikas resulted in three distinct projects: Open Cycles (Bath, 2016), Toxic Gum (Berlin, 2017) and Azoman (London, 2018). I will present audiovisual material and patches from these three collaborations, which next to the GesTCom feature Ghikas's unreal-time improve system. I will show how the GesTCom was used both as a generator of pre-compositional material and as a real-time tool enabling allelomimetic interactions based on gesture in both solo, duo and ensemble settings.  I will also expand on the underlying concepts of embodied navigation of complex notation and of unreal-time improv as promoting the complementarity of improvisation and composition and the fluidity between notation, motion and sound in piano performance.

***12:45***
#### Disposable Music
Georg Hajdu

My presentation introduces the concept of real-time composition and composition as a dispositif in the sense of Foucault and Deleuze, defining it as a heterogeneous ensemble of pieces which together form an apparatus. The introduction situates the dispositif in the context of cultural developments, most notably its slow, but steady shift away from textualization in digital media. As musicians are adapting to ensuing cultural and, above all, economic changes, new music forms emerge which rely to a lesser degree on fully-notated scores such as comprovisation or laptop performance. Antithetically, the computer also allows the creation of “author-less” notated scores in real-time to be sight-read by capable musicians—a practice for which special software has been developed in recent years. Since these scores are not meant to be kept and distributed, they are ephemeral and, therefore, disposable. Examples are given to illustrate the interwovenness of this approach, where carefully selected narratives and dramaturgies make up for the inherent unpredictability of the outcome.

<br>

<font color="DarkBlue">
***13:30***
#### *Lunch Break*
UOA Cultural building Kostis Palamas
</font>
<br><br><br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Saturday sept 28 - Workshops
**Onassis Cultural Center, 16:00 - 19:00**
### Game, mobiles, transducers
</font>
<br>
<br>

***16:00 - 17:00***
#### The Dynamic Percussion System: A procedural music engine for video games
Daniel Brown (Intelligent Music System, USA)

The Dynamic Percussion System is software used in commercial video games like Rise of the Tomb Raider (2015) that composes procedural percussion music that adapts to game action in real time.<br>
While the use of procedural music in video games is an exciting development, there are many unanswered questions and issues surrounding it. How does it fit into the traditional workflow of professional composers and sound designers? What choices do such people have when “authoring” procedural music? How does it interact with precomposed game music?  
The Dynamic Percussion System comprises both an in-game playback system and an authoring tool to be used by composers and sound designers. The design of the authoring tool––its user interface and functionality––addresses these questions. It offers one model of how the new techniques of generating procedural music can be adapted into the traditional methods used in commercial development. It has also motivated new techniques for generating, implementing, and interpreting game music.

***17:00 - 18:00***
#### Improvisation with Motion Sensors and Live coding: Combining Dance and Instrumental Improvisation
Ioannis Zannos (Ionian University, Gr.)

This workshop introduces techniques of improvisation with wearable movement sensors combined with live coding.  Movement sensors based on IMU (Inertial Measurement Units) are used to measure the movement of a performer.  The motion data is transmitted to computer over wifi, and live coding is used to control the generation of sound in SuperCollider and graphics on the Godot Gaming engine.  The workshop shows how to use the sc-hacks library in order to program and modify the response of the system to sensor data.  Techniques for sending the control data to remote locations over the internet are shown.  This enables joint performance from several different remote locations. At each location the data sent from all performers is used to synthesize the audiovisual performance.

***18:00 - 19:00***
#### Composing “musiques mixtes” : acoustic spaces, improvisation and gestures.
Lara Morciano (composer, It.), Jose-Miguel Fernandez (composer, Ircam, Fr.)

The workshop introduces some possibilities of real-time interaction between instruments and electronic, explored through a device which uses the hands movements of the performer to control and synchronize various sound processes.
This presentation will mainly focus on the Philiris composition for piano, motion capture and transducers. The different sections of the piece will be presented from a technical and compositional point of view. Examples of the interaction between the real and virtual piano linked to motion capture, sound synthesis and real time treatments through transducers within the piano and the notion of "double" will be presented. It will also show examples of Antescofo, score follower and programming language software, for the creation of real-time processes and interaction in relation with the notions of acoustic spaces, improvisation and gestures.


<br>
<br>

<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Saturday sept 28 - Concert
**Onassis Cultural Center, 20:00 - 22:30**
<br><br><br>
</font>
<br>
<br>

***20:00***
#### Concert #3

[*Program Notes*]({filename}/pages/ProgramNote_Concert3.md)

**Jaap Blonk, Hervé Sellin, Georges Bloch**  
*Paris bout à bout*  
Cine-concert on Nurith Aviv's *Bout à Bout* movie. Voice, piano, OMax and DYCI2 computer systems.

**Mark Bokowiec and Julie Wilson - Bokowiec**  
*HEXIS*  
For Kinaesonics, Bodycoder System and soloist.

**Marc Chemillier and Camel Zekri**  
*Gnawa Machine*  
Augmented guitar, keyboard, dJazz and Le Cercle computer systems.

**Orestis Karamanlis and Giorgos Gargalas**
*BitVox*
For beatboxing and laptop live electronics

**Steve Lehman and Jerôme Nika**  
*Silver Lake Studies*  
Saxophones, live electronics, DYCI2 computer system


<br>
<br>


<img src="../images/IKPoster_frag16.png" width="260" style="float:left" hspace="30">
<font color="DarkBlue">
# Sunday Sept 29 - Lectures
**Onassis Cultural Center, 09:30 - 13:30**
### Aesthetics and Ethics of Improvisation in the Digital Era
</font>
<br>
<br>

***09:30***
#### Keynote talk : Distributed Creativity, Some Ethical Aspects of Group Improvisation, and our (human-like) Interaction with Digital Entities
Garry L. Hagberg (Bard College, USA)

The work of an improvising ensemble is intentional action, but of a kind -- a collective kind -- that transcends the sum total of the intentions of individual players. And while performing, players face emergent and rapidly-shifting obligations to each other, to the collective, and to the traditions and histories to which they are contributing. Thus in improvising ensembles we work together in a special way, and we treat or regard each other in a special (closely-listening, closely-responding) way. The digital age of computer interaction lifts these issues to a new level of complexity: do we see the co-improvising program as a co-equal participant to whom (or to "whom") we distribute creative agency; do we have ethical obligations of a similar kind -- not to her or to him -- but to it? This talk will pursue these issues by offering some ways of thinking of (1) collective improvisational creativity, (2) ethical interaction within an improvising ensemble, and (3) the form of "seeing as" that places us into a human-like relationship with artificial musical intelligence.

***10:15***
#### The MICA Project : Musical Improvisation and Collective Action
Clement Canonne (Ircam, CNRS, Fr.) & Pierre Saint Germier (Ircam, Fr.)

Pierre Saint Germier: Interaction and Improvisation in Human and Artificial Musicians. A conceptual approach<br>
In this talk, I will first discuss conceptual analyses of the notions of interaction and improvisation in music from the standpoint of the philosophy of action. In particular, I will contend that interaction and improvisation are best conceived as overlapping but importantly distinct notions. I will also present and evaluate a set of positive criteria for improvised action (as opposed to merely negative criteria such as "unplanned" or "unscripted"). In the second part of the talk, I will discuss how these notions can be applied to music-making settings involving artificial entities, such as software or robots.*

***10:45***
#### Machine Ethics and Music Creativity
George Kosteletos, Αnastasia Georgaki (University of Athens, Gr.)

While tackling the issues of Machine Ethics from the perspective of possibly intelligent machines, one has to face questions related to the attribution of rights to such mechanical entities. Given that in the last seven or more decades computational systems have been involved in the production of more or less organized sound structures characterized as works of art, one of the machine rights in question is the right of authorship. In its turn, this right is interconnected with a set of other rights and questions like copyright issues (the legal and financial side of the right of authorship), one’s right to be appreciated for one’s own work as well as questions regarding the ontology of the mechanic output (Is it an artistic or just an aesthetic object?). However, answering these questions presupposes the attribution of intelligence to the machines involved in the production of such an output. Could the production of an aesthetically laden output be thought of as a genuine manifestation of intelligence or do we need the application of extra criteria? Our previous experience of designing and running various forms of musical Turing Tests (musical TT) has shown that the criterion of music creativity suffers from the same problems and limitations of any other intelligence criterion applied in the past. Nevertheless, there seems to be a special case of music creativity: music improvisation. So the question arises: Could music improvisation with its spontaneous and dialectical (in the case of human-machine interaction in the context of live electronics) nature be a safe indication of machine intelligence, bypassing the problems of traditional intelligence criteria? Two case studies of music improvisation AI systems are examined.

<font color="DarkBlue">
***11:15***
#### *Coffee Break*
</font>

***11:45***
#### AI-Aesthetics. Artificial Intelligence in Music and Art
Harry Lehmann (Philosopher, DE)

In the field of Artificial Intelligence (AI), impressive progress has been made in recent years, especially due to the development of deep learning systems. After the first applications of such programs in art and music, it is becoming apparent that a new aesthetic discipline could develop here (in analogy to how advances in computed tomography led to the formation of neuroaesthetics two decades ago). The obvious suggestion would be to speak of AI-aesthetics here. Thus, for example, a deep learning system was trained to abstract the corresponding stylistic features from many examples of a particular painting style, such as Cubism or Expressionism. As a result, it became possible to convert any photo, such as your own portrait, into a Cubist or Expressionist style.<br>
The aim of my lecture will be, on the one hand, to describe the phenomena that fall within the scope of such AI-aesthetics. These include works of art and musical compositions that were 'calculated' using AI programs. Similarly, recommender systems that make aesthetic decisions using AI algorithms fall into this area. On the other hand, I would like to try to gauge the consequences of this for both art and music as well as art and music theory.

***12:15***
#### The phenomenology of computer aided improvisation and the constitution of the virtual music subject
Iakovos Steinhauer (University of Athens, Gr.)

Improvisation is a practice free from any pre-established system, based mainly in interaction, namely the aim to become a part of the other, to feel, think and act not only following the subjective assessments but by adapting the play behavior of the improvisation partner. In case of improvisation between a player and the computer music derives from a continuous circuit of mediations, complex real time- interactive responses to the musician’s playing. The computer aided improvisation provides empirical insight into the reversible, dialectical, and signifying nature of a virtual embodiment, where the player acts by feeling his limited body in interaction with an incomplete, not yet self conscious but potential limitless body-subject. The purpose of this paper is to undertake philosophical reflections upon computer assisted improvisation. We see the digital improvisation experience as a process that finds its foundation in a mutually shared space, constituting both the augmented subjective musical body of the musician and the virtual computer subject, providing new forms of self consciousness in creation.

***12:45***
#### Improvising (with) awkwardness
Danae Stefanou (Aristotle University of Thessaloniki, Gr.)

In modern Greek, the term “amechania” roughly translates as “awkwardness”. It owes its name to the ancient Greek deity of Helplessness, a spirit linked to times of crisis and want. Literally translatable as a “de-machination”, it essentially describes the critical state when a mechanism fails, and otherwise automated procedures are rendered inoperative. Yet, unreliable systems and failing machines, whether in the form of technological apparatuses or cognitive procedures, also tend to yield their own unforeseen byproducts. When a machine is de-instrumentalised, when its prescribed function is not executable and its use no longer discernible, divisions between subject and object, freedom and control, process and product may be more easily exposed, unpacked, and relativized. Discussing such liminal instances in recent examples of improvised music, I examine the broader theoretical implications of this concept, with reference to the work of Giorgio Agamben and Donna Haraway among others, and propose an active exploration of amechania as a positive aspiration for experimental and improvised music-making in the age of machinic capitalism.

***13:30***
#### Closing words

<br><br>


---

<p align="center">
   <br><br>
  <img src="../images/IKPoster_frag10.png" width="300">
   <br><br>
</p>
